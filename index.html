<!doctype html>
<html>

<head>
<title>Lue Fan</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Lue Fan, NLPR, Institute of Automation, Chinese Academy of Sciences"> 
<meta name="description" content="Lue Fan's home page">
<link rel="stylesheet" href="template.css" type="text/css" />

<!-- Show more content -->
<script type="text/javascript">
    function toggle_vis(id) {
        var e = document.getElementsByClassName(id);
        var showText = document.getElementById("showText");
        for (var i = 0; i < e.length; i++) {
            if (e[i].style.display == "none") {
                e[i].style.display = "inline";
                showText.innerHTML = "[Show less]";
            } else {
                e[i].style.display = "none";
                showText.innerHTML = "[Show more]";
            }
        }
    }

    // Image preview functionality
    function showImagePreview(imgSrc) {
        var preview = document.getElementById('imagePreview');
        var previewImg = document.getElementById('previewImg');
        previewImg.src = imgSrc;
        preview.style.display = 'flex';
    }

    function hideImagePreview() {
        var preview = document.getElementById('imagePreview');
        preview.style.display = 'none';
    }

    // Initialize image preview functionality when page loads
    document.addEventListener('DOMContentLoaded', function() {
        var publicationImages = document.querySelectorAll('.publication_image img');
        publicationImages.forEach(function(img) {
            img.addEventListener('click', function() {
                showImagePreview(this.src);
            });
        });
    });
</script>

</head>

<body>

<!-- Image Preview Modal -->
<div id="imagePreview" class="image-preview" onclick="hideImagePreview()">
    <img id="previewImg" src="" alt="Preview">
</div>

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Lue Fan (范略)<h1>
				</div>

                <h3 class="title">Assistant Professor</h3>

				<p>
                    NLPR (模式识别实验室), Institute of Automation</br>
                    Chinese Academy of Sciences</br>
					</br>
                    Email: lue.fan at ia.ac.cn </br>
					</br>
                    [<a href="https://scholar.google.com/citations?user=6ZzmkHEAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a>][<a href="https://github.com/Abyssaledge">GitHub</a>] </br>
				</p>

			</td>
			<td width="25%">
				<img src="images/photo.jpg" width="100%"/>
			</td>
		<tr>
	</tbody>
</table>

<h2>About Me</h2> 

<div style="display: flex">
    <p>
        I am currently an assistant professor in NLPR, Institute of Automation, Chinese Academy of Sciences. I got my Ph.D. degree from this lab in June 2024, supervised by Prof. <a href="https://zhaoxiangzhang.net/chinese/">Zhaoxiang Zhang</a>, and bachelor's degree from Xi'an Jiaotong University (XJTU) in 2019, majoring in automation. I was a research intern at TuSimple developing perception algorithm for autonomous trucks from May 2020 to April 2023, supervised by Dr. <a href="https://scholar.google.com/citations?user=yAWtq6QAAAAJ&hl=en">Naiyan Wang</a> and Dr. <a href="https://happynear.wang/">Feng Wang</a>.</br>
    </p>
</div>

<div style="display: flex; margin-bottom: -10px">
    <p>
        My research interests focus on the <strong>perception/decision/simulation</strong> algorithms in autonomous driving scenarios. During Ph.D., my representative research lies in a series of algorithms for <strong>LiDAR-based fully sparse detection</strong>, supporting the super long-range perception and enhancing the driving safety. Currently, I am mainly focusing on driving simulation and work closely with Prof. <a href="https://www.ee.cuhk.edu.hk/~hsli/">Hongsheng Li</a> @ MMLab.
    </p>
</div>

<h2>News</h2>

<ul>
    <!-- <li> -->
        <!-- <div class="marker">[2025-08] Received the Chinese Academy of Sciences Outstanding Doctoral Dissertation Award!</div> -->
    <!-- </li> -->
    <li>
        <div class="marker">[2025-07] Three papers accepted to ICCV 2025!</div>
    </li>
    <li>
        <div class="marker">[2025-02] FreeSim and FlexDrive accepted by CVPR 2025!</div>
    </li>
    <li>
        <div class="marker">[2025-01] LAW accepted by ICLR 2025!</div>
    </li>
</ul>

<div class="show_button">
    <a href="javascript:toggle_vis('news')" id="showText">[Show more]</a>
</div>

<h2>Research Summary</h2>

<p>
My research spans three key areas in autonomous driving: <strong>perception</strong>, <strong>decision-making</strong>, and <strong>simulation</strong>. I have developed groundbreaking algorithms for LiDAR-based fully sparse 3D object detection, enabling super long-range perception capabilities for autonomous driving systems.
</p>

<p>
Recently, I focus on driving simulation technologies, including novel view synthesis and world models for autonomous driving systems. My work aims to bridge the gap between simulation and real-world autonomous driving scenarios.
</p>

<h2>Selected Work</h2>

<p>*: Equal Contribution; †: Corresponding Author</p>

<h3>2025</h3>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/wote.png">
    </div>
    <div class="publication_title">
        End-to-End Driving with Online Trajectory Evaluation via BEV World Model</br>
        Yingyan Li, Yuqi Wang, Yang Liu, Jiawei He, <strong>Lue Fan†</strong>, Zhaoxiang Zhang†</br>
        <em>ICCV 2025</em></br>
        [<a href="https://arxiv.org/abs/2504.01941">Paper</a>][<a href="https://github.com/liyingyanUCAS/WoTE">Code</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/layeranimate.png">
    </div>
    <div class="publication_title">
        LayerAnimate: Layer-level Control for Animation</br>
        Yuxue Yang, <strong>Lue Fan</strong>, Zuzeng Lin, Feng Wang, Zhaoxiang Zhang</br>
        <em>ICCV 2025</em></br>
        [<a href="https://arxiv.org/abs/2501.08295">Paper</a>][<a href="https://layeranimate.github.io">Project Page</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/freesim_teaser.png">
    </div>
    <div class="publication_title">
        FreeSim: Toward Free-viewpoint Camera Simulation in Driving Scenes</br>
        <strong>Lue Fan*</strong>, Hao Zhang*, Qitai Wang, Hongsheng Li†, Zhaoxiang Zhang†</br>
        <em>CVPR 2025</em></br>
        [<a href="https://arxiv.org/abs/2412.03566">Paper</a>][<a href="https://drive-sim.github.io/freesim">Project Page</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/flexdrive.png">
    </div>
    <div class="publication_title">
        FlexDrive: Toward Trajectory Flexibility in Driving Scene Reconstruction and Rendering</br>
        Jingqiu Zhou*, <strong>Lue Fan*</strong>, Linjiang Huang, Xiaoyu Shi, Si Liu, Z. Zhang†, Hongsheng Li†</br>
        <em>CVPR 2025</em></br>
        [<a href="https://arxiv.org/abs/2502.21093">Paper</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/freevs_teaser.png">
    </div>
    <div class="publication_title">
        FreeVS: Generative View Synthesis on Free Driving Trajectory</br>
        Qitai Wang, <strong>Lue Fan</strong>, Yuqi Wang, Yuntao Chen†, Zhaoxiang Zhang†</br>
        <em>ICLR 2025</em></br>
        [<a href="https://arxiv.org/abs/2410.18079">Paper</a>][<a href="https://freevs24.github.io/">Project Page</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/law_teaser.png">
    </div>
    <div class="publication_title">
        Enhancing End-to-End Autonomous Driving with Latent World Model</br>
        Yingyan Li, <strong>Lue Fan</strong>, Jiawei He, Yuqi Wang, Yuntao Chen, Zhaoxiang Zhang, Tieniu Tan</br>
        <em>ICLR 2025</em></br>
        [<a href="https://arxiv.org/abs/2406.08481">Paper</a>][<a href="https://github.com/BraveGroup/LAW">Code</a>]</br>
    </div>
</div>

<h3>2024</h3>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/fsdv2_teaser.png">
    </div>
    <div class="publication_title">
        FSD V2: Improving Fully Sparse 3D Object Detection with Virtual Voxels</br>
        <strong>Lue Fan</strong>, Feng Wang, Naiyan Wang, Zhaoxiang Zhang</br>
        <em>TPAMI 2024</em></br>
        [<a href="https://arxiv.org/abs/2308.03755">Paper</a>][<a href="https://github.com/TuSimple/SST">Code</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/opensatmap_teaser.png">
    </div>
    <div class="publication_title">
        OpenSatMap: A Fine-grained High-resolution Satellite Dataset for Large-scale Map Construction</br>
        Hongbo Zhao, <strong>Lue Fan</strong>, Yuntao Chen, Haochen Wang, Yuran Yang, Xiaojuan Jin, Yixin Zhang, Gaofeng Meng, Zhaoxiang Zhang</br>
        <em>NeurIPS 2024 D&B Track</em></br>
        [<a href="https://arxiv.org/abs/2410.23278">Paper</a>][<a href="https://opensatmap.github.io/">Project Page</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/trimgs_teaser.png">
    </div>
    <div class="publication_title">
        Trim 3D Gaussian Splatting for Accurate Geometry Representation</br>
        <strong>Lue Fan*</strong>, Yuxue Yang*, Minxing Li, Hongsheng Li†, Zhaoxiang Zhang†</br>
        [<a href="https://arxiv.org/abs/2406.07499">Paper</a>][<a href="https://github.com/YuxueYang1204/TrimGS">Code</a>][<a href="https://trimgs.github.io/">Project Page</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/voxelmamba_teaser.png">
    </div>
    <div class="publication_title">
        Voxel Mamba: Group-Free State Space Models for Point Cloud based 3D Object Detection</br>
        Guowen Zhang, <strong>Lue Fan</strong>, Chenhang He, Zhen Lei, Zhaoxiang Zhang, Lei Zhang</br>
        <em>NeurIPS 2024</em></br>
        [<a href="https://arxiv.org/abs/2406.10700">Paper</a>][<a href="https://github.com/gwenzhang/Voxel-Mamba">Code</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/wm_teaser.png">
    </div>
    <div class="publication_title">
        Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving</br>
        Yuqi Wang*, Jiawei He*, <strong>Lue Fan*</strong>, Hongxin Li*, Yuntao Chen†, Zhaoxiang Zhang†</br>
        <em>CVPR 2024</em></br>
        [<a href="https://arxiv.org/abs/2311.17918">Paper</a>][<a href="https://github.com/BraveGroup/Drive-WM">Code</a>][<a href="https://drive-wm.github.io">Project Page</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/mixsup_teaser.png">
    </div>
    <div class="publication_title">
        MixSup: Mixed-grained Supervision for Label-efficient LiDAR-based 3D Object Detection</br>
        Yuxue Yang, <strong>Lue Fan†</strong>, Zhaoxiang Zhang†</br>
        <em>ICLR 2024</em></br>
        [<a href="https://arxiv.org/abs/2401.16305">Paper</a>][<a href="https://github.com/BraveGroup/PointSAM-for-MixSup">Code</a>]</br>
    </div>
</div>

<h3>2023</h3>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/ctrl_teaser.png">
    </div>
    <div class="publication_title">
        Once Detected, Never Lost: Surpassing Human Performance in Offline LiDAR based 3D Object Detection (CTRL)</br>
        <strong>Lue Fan</strong>, Yuxue Yang, Yiming Mao, Feng Wang, Yuntao Chen, Naiyan Wang, Zhaoxiang Zhang</br>
        <em>ICCV 2023 (<span style="color: #e74c3c; font-weight: bold;">Oral</span>)</em></br>
        [<a href="https://arxiv.org/abs/2304.12315v1">Paper</a>][<a href="https://github.com/TuSimple/SST">Code</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/fsdpp_teaser.png">
    </div>
    <div class="publication_title">
        Super Sparse 3D Object Detection (FSD++)</br>
        <strong>Lue Fan</strong>, Yuxue Yang, Feng Wang, Naiyan Wang, Zhaoxiang Zhang</br>
        <em>TPAMI 2023</em></br>
        [<a href="https://arxiv.org/abs/2301.02562">Paper</a>][<a href="https://github.com/TuSimple/SST">Code</a>]</br>
    </div>
</div>

<h3>2022</h3>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/fsd_teaser.png">
    </div>
    <div class="publication_title">
        Fully Sparse 3D Object Detection (FSD)</br>
        <strong>Lue Fan</strong>, Feng Wang, Naiyan Wang, Zhaoxiang Zhang</br>
        <em>NeurIPS 2022</em></br>
        [<a href="https://arxiv.org/abs/2207.10035">Paper</a>][<a href="https://github.com/TuSimple/SST">Code</a>]</br>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/sst_teaser.png">
    </div>
    <div class="publication_title">
        Embracing Single Stride 3D Object Detector with Sparse Transformer (SST)</br>
        <strong>Lue Fan</strong>, Ziqi Pang, Tianyuan Zhang, Yu-Xiong Wang, Hang Zhao, Feng Wang, Naiyan Wang, Zhaoxiang Zhang</br>
        <em>CVPR 2022</em></br>
        [<a href="https://arxiv.org/abs/2112.06375">Paper</a>][<a href="https://github.com/TuSimple/SST">Code</a>]</br>
    </div>
</div>

<h3>2021</h3>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/rangedet_teaser.png">
    </div>
    <div class="publication_title">
        RangeDet: In Defense of Range View for Lidar-based 3D Object Detection</br>
        <strong>Lue Fan*</strong>, Xuan Xiong*, Feng Wang, Naiyan Wang, Zhaoxiang Zhang</br>
        <em>ICCV 2021</em></br>
        [<a href="https://arxiv.org/abs/2103.10039">Paper</a>][<a href="https://github.com/TuSimple/RangeDet">Code</a>]</br>
    </div>
</div>

<div id="footer">
<div id="footer-text">
<!-- <script type="text/javascript" src="https://www.free-counters.org/count/frj4"></script><br> -->
<em>This website was automatically generated from personal information using Claude Code.</em>
</div>
</div>

</div>

</body>
</html>